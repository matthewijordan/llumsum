Here’s a high-level design and implementation guide for the `llumsum` tool.

---

# 🧠 `llumsum` – LLM-Powered Codebase Summarizer

## 📌 Summary

`llumsum` is a lightweight, language-agnostic summarization tool for source code projects, designed to assist large language model agents and developer tools by maintaining structured, high-level summaries of code files. It mirrors a project’s directory tree in a hidden `.llumsum/` folder, storing plain-text summaries and metadata (like content hashes) to track and manage source understanding at scale.

It is intended as a reusable library and CLI companion module, with modular encapsulation and clean API surface, and integrates with LangChain to allow flexible LLM backend selection.

---

## 🎯 Motivation

AI coding assistants and agents suffer from context limitations and expensive re-ingestion of large or irrelevant files. Human developers solve this with mental models: knowing which files matter and what they do at a glance.

`llumsum` formalizes that intuition: a tool- and language-neutral system that summarizes what a file does, what it exports, and what workflows it’s part of—storing this alongside the project for fast retrieval and incremental regeneration.

---

## 🛠️ Intended Use Cases

* **CLI-based LLM assistants** to load summaries of relevant files instead of raw code
* **Multi-agent LLM systems** to determine file relevance, search paths, or perform scoped planning
* **Developer productivity tools** to provide lightweight, browsable overviews of large codebases
* **Offline or background summarization** using file watchers or git hooks

---

## 🧱 High-Level Architecture

```
my-project/
├── src/
│   └── main.ts
└── .llumsum/
    └── src/
        └── main.ts.summary
```

Each `.summary` file contains:

* A hash of the file content (used for staleness detection)
* A free-form natural language summary (generated by an LLM)

---

## 📦 Module Structure (Proposed)

```
packages/llumsum/
├── src/
│   ├── index.ts                  // Public API
│   ├── summarizer/               // LangChain + LLM interfaces
│   ├── fs/
│   │   ├── layout.ts             // Summary path resolution logic
│   │   ├── readWrite.ts          // File system helpers
│   │   └── hash.ts               // Hashing utilities
│   ├── cli/
│   │   └── index.ts              // Optional CLI integration
│   └── types/
│       └── summary.ts            // Type definitions
├── .env                         // Optional, for model/backend config
└── package.json
```

---

## 🧩 Key Components

### 1. **File Mirroring Layer**

* Resolves `.llumsum/` mirror path for a given source file
* Ensures directory structure is created on demand
* Mirrors source file locations exactly, appending `.summary` as extension

### 2. **Summary Format**

* First line: `hash: <sha1>` (or other hash)
* Body: LLM-generated free-form natural language summary

  * High-level file purpose
  * Exported symbols & their roles
  * Important workflows or side effects

### 3. **LLM Summarizer (LangChain-based)**

* Abstracted LangChain `Runnable` chain for prompt + model interaction
* Model and prompt templates driven via environment variables:

  * e.g. `LLM_PROVIDER=openai`, `LLM_MODEL=gpt-4-turbo`
* Auto-selection of appropriate chain (streaming, retry, etc.) based on config

### 4. **Hashing & Sync Logic**

* Efficient content hash comparison (e.g. SHA-1)
* Dirty detection: file hash mismatch triggers regeneration
* Optional file watcher or CLI `sync` command to batch update summaries

### 5. **Public API Surface**

```ts
// Read a summary (regenerates if needed)
readOrGenerateSummary(filePath: string): Promise<SummaryResult>

// Force regeneration
generateSummary(filePath: string): Promise<SummaryResult>

// Read summary (no LLM fallback)
readSummaryFile(filePath: string): Promise<SummaryResult | null>

// Utility: check if summary is stale
isStale(filePath: string): Promise<boolean>
```

---

## 🖥️ CLI Interface (Optional)

```bash
llumsum sync               # Regenerates stale summaries
llumsum summary path.ts    # Reads or generates a single summary
llumsum clean              # Removes orphan summaries
```

---

## 🔐 Design Principles

* **Encapsulation**: Filesystem logic, LangChain config, and summary format are separated
* **Stateless Core**: Summary logic is deterministic and easy to run in CI, watch loops, or remote agents
* **Composable**: Designed for direct use in CLI tools, LLM orchestrators, or background services
* **Extensible**: Support for multiple summary styles (e.g. docstring-only, full workflow) in future
* **Provider-Agnostic**: Supports any LangChain-compatible model; selection is fully externalized

---

## 🌱 Future Considerations

* Summary caching/indexing (e.g. `.llumsum/manifest.json`)
* Git integration: generate summaries on diffs or pre-commit
* Language-aware extensions (e.g. function signature detection from AST)
* Custom prompt styles per project/language

---

Let me know if you'd like this written up as a Markdown `README.md` or `DESIGN.md` for your repo.
