Hereâ€™s a high-level design and implementation guide for the `llumsum` tool.

---

# ğŸ§  `llumsum` â€“ LLM-Powered Codebase Summarizer

## ğŸ“Œ Summary

`llumsum` is a lightweight, language-agnostic summarization tool for source code projects, designed to assist large language model agents and developer tools by maintaining structured, high-level summaries of code files. It mirrors a projectâ€™s directory tree in a hidden `.llumsum/` folder, storing plain-text summaries and metadata (like content hashes) to track and manage source understanding at scale.

It is intended as a reusable library and CLI companion module, with modular encapsulation and clean API surface, and integrates with LangChain to allow flexible LLM backend selection.

---

## ğŸ¯ Motivation

AI coding assistants and agents suffer from context limitations and expensive re-ingestion of large or irrelevant files. Human developers solve this with mental models: knowing which files matter and what they do at a glance.

`llumsum` formalizes that intuition: a tool- and language-neutral system that summarizes what a file does, what it exports, and what workflows itâ€™s part ofâ€”storing this alongside the project for fast retrieval and incremental regeneration.

---

## ğŸ› ï¸ Intended Use Cases

* **CLI-based LLM assistants** to load summaries of relevant files instead of raw code
* **Multi-agent LLM systems** to determine file relevance, search paths, or perform scoped planning
* **Developer productivity tools** to provide lightweight, browsable overviews of large codebases
* **Offline or background summarization** using file watchers or git hooks

---

## ğŸ§± High-Level Architecture

```
my-project/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ main.ts
â””â”€â”€ .llumsum/
    â””â”€â”€ src/
        â””â”€â”€ main.ts.summary
```

Each `.summary` file contains:

* A hash of the file content (used for staleness detection)
* A free-form natural language summary (generated by an LLM)

---

## ğŸ“¦ Module Structure (Proposed)

```
packages/llumsum/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ index.ts                  // Public API
â”‚   â”œâ”€â”€ summarizer/               // LangChain + LLM interfaces
â”‚   â”œâ”€â”€ fs/
â”‚   â”‚   â”œâ”€â”€ layout.ts             // Summary path resolution logic
â”‚   â”‚   â”œâ”€â”€ readWrite.ts          // File system helpers
â”‚   â”‚   â””â”€â”€ hash.ts               // Hashing utilities
â”‚   â”œâ”€â”€ cli/
â”‚   â”‚   â””â”€â”€ index.ts              // Optional CLI integration
â”‚   â””â”€â”€ types/
â”‚       â””â”€â”€ summary.ts            // Type definitions
â”œâ”€â”€ .env                         // Optional, for model/backend config
â””â”€â”€ package.json
```

---

## ğŸ§© Key Components

### 1. **File Mirroring Layer**

* Resolves `.llumsum/` mirror path for a given source file
* Ensures directory structure is created on demand
* Mirrors source file locations exactly, appending `.summary` as extension

### 2. **Summary Format**

* First line: `hash: <sha1>` (or other hash)
* Body: LLM-generated free-form natural language summary

  * High-level file purpose
  * Exported symbols & their roles
  * Important workflows or side effects

### 3. **LLM Summarizer (LangChain-based)**

* Abstracted LangChain `Runnable` chain for prompt + model interaction
* Model and prompt templates driven via environment variables:

  * e.g. `LLM_PROVIDER=openai`, `LLM_MODEL=gpt-4-turbo`
* Auto-selection of appropriate chain (streaming, retry, etc.) based on config

### 4. **Hashing & Sync Logic**

* Efficient content hash comparison (e.g. SHA-1)
* Dirty detection: file hash mismatch triggers regeneration
* Optional file watcher or CLI `sync` command to batch update summaries

### 5. **Public API Surface**

```ts
// Read a summary (regenerates if needed)
readOrGenerateSummary(filePath: string): Promise<SummaryResult>

// Force regeneration
generateSummary(filePath: string): Promise<SummaryResult>

// Read summary (no LLM fallback)
readSummaryFile(filePath: string): Promise<SummaryResult | null>

// Utility: check if summary is stale
isStale(filePath: string): Promise<boolean>
```

---

## ğŸ–¥ï¸ CLI Interface (Optional)

```bash
llumsum sync               # Regenerates stale summaries
llumsum summary path.ts    # Reads or generates a single summary
llumsum clean              # Removes orphan summaries
```

---

## ğŸ” Design Principles

* **Encapsulation**: Filesystem logic, LangChain config, and summary format are separated
* **Stateless Core**: Summary logic is deterministic and easy to run in CI, watch loops, or remote agents
* **Composable**: Designed for direct use in CLI tools, LLM orchestrators, or background services
* **Extensible**: Support for multiple summary styles (e.g. docstring-only, full workflow) in future
* **Provider-Agnostic**: Supports any LangChain-compatible model; selection is fully externalized

---

## ğŸŒ± Future Considerations

* Summary caching/indexing (e.g. `.llumsum/manifest.json`)
* Git integration: generate summaries on diffs or pre-commit
* Language-aware extensions (e.g. function signature detection from AST)
* Custom prompt styles per project/language

---

Let me know if you'd like this written up as a Markdown `README.md` or `DESIGN.md` for your repo.
